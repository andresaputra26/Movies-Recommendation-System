# -*- coding: utf-8 -*-
"""Movie Recommendation System.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18VyUO_5t3tD9_YPd62H7L2y54g_Wi7R6

# Movie Recommendation System

Nama : Andre Saputra Ginting

Username : andresaputra26

Email : andresaputra260604@gmail.com

## Latar Belakang

Pertumbuhan industri perfilman, baik di tingkat internasional maupun nasional, menunjukkan perkembangan yang sangat menjanjikan. Hal ini tercermin dari peningkatan jumlah penonton bioskop yang terus bertambah setiap tahunnya. Pada tahun 2018, jumlah penonton bioskop di Indonesia telah melampaui 50 juta orang, dengan hampir 200 judul film dari produksi dalam dan luar negeri yang telah diputar di seluruh wilayah Indonesia (Prasetyo & Nugroho, 2022). Dalam industri perfilman, pengelompokan penonton dilakukan melalui kategori tertentu seperti klasifikasi usia dan pemilihan genre pada setiap film yang diproduksi. Oleh karena itu, diperlukan sistem rekomendasi yang mampu membantu penonton dalam menentukan genre film yang sesuai dengan preferensi serta batasan usia mereka (Nababan & Trisna, 2021).

Untuk mengatasi permasalahan dalam pemberian rekomendasi film, salah satu solusi yang diterapkan adalah penggunaan metode content-based filtering. Teknik ini bekerja dengan memanfaatkan informasi dari atribut-atribut film seperti genre, nama sutradara, aktor utama, serta ringkasan cerita. Dengan menganalisis kemiripan antar atribut tersebut, sistem mampu mengenali hubungan antar film dan memberikan rekomendasi berdasarkan kesamaan karakteristik. Ketika pengguna menyukai atau tertarik pada sebuah film, sistem secara otomatis menyarankan film lain yang memiliki profil serupa. Pendekatan ini bertujuan untuk meningkatkan relevansi hasil rekomendasi serta kepuasan pengguna terhadap sistem (Zakharia et al., 2024).

Selain pendekatan content-based filtering, metode lain yang umum digunakan dalam sistem rekomendasi adalah Collaborative Filtering (CF). Metode ini bekerja dengan memprediksi preferensi atau ketertarikan seorang pengguna terhadap suatu item berdasarkan kesamaan pola perilaku dan penilaian dari pengguna lain. CF mengandalkan data seperti rating yang diberikan oleh pengguna untuk mengidentifikasi hubungan antar pengguna dan merekomendasikan item yang disukai oleh pengguna dengan preferensi serupa. Selain rating, proses ini juga melibatkan evaluasi item melalui opini atau pengalaman pengguna lain, sehingga sistem dapat memberikan rekomendasi yang lebih personal dan relevan (Agustian et al., 2020).

Proyek sistem rekomendasi film menggunakan Content-Based Filtering dan Collaborative Filtering penting diselesaikan karena membantu pengguna menemukan film yang sesuai dengan preferensi mereka secara efisien di tengah banyaknya pilihan yang tersedia. Content-Based Filtering memberikan rekomendasi berdasarkan karakteristik film yang disukai pengguna, sementara Collaborative Filtering memanfaatkan pola preferensi pengguna lain untuk memberikan rekomendasi yang lebih beragam dan relevan. Penggabungan kedua metode ini dapat meningkatkan akurasi dan variasi rekomendasi, sekaligus mengatasi keterbatasan masing-masing pendekatan. Dengan sistem rekomendasi yang efektif, pengalaman pengguna menjadi lebih personal dan menyenangkan, sekaligus mendukung penyedia layanan dalam memahami dan memenuhi kebutuhan pengguna dengan lebih baik.

# Import Library
"""

!pip install opendatasets
import pandas as pd
import numpy as np
import opendatasets as od
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from pathlib import Path
import matplotlib.pyplot as plt

"""# Load Dataset"""

od.download("https://www.kaggle.com/datasets/nicoletacilibiu/movies-and-ratings-for-recommendation-system?select=movies.csv")

movies = pd.read_csv("/content/movies-and-ratings-for-recommendation-system/movies.csv")
ratings = pd.read_csv("/content/movies-and-ratings-for-recommendation-system/ratings.csv")

"""# Data Understanding

## Movies Dataset
"""

movies.head()

# List untuk menyimpan ringkasan per kolom
list_of_descs = []

# Menggunakan dataframe 'movies' sebagai contoh, ganti dengan 'ratings' jika perlu
for col in movies.columns:
    col_type = movies[col].dtype
    total_row = movies.shape[0]
    null_count = movies[col].isna().sum()
    null_pct = round((null_count / total_row) * 100, 2)
    unique_count = movies[col].nunique()
    sample_unique = movies[col].unique()

    list_of_descs.append([
        col,
        col_type,
        total_row,
        null_count,
        null_pct,
        unique_count,
        sample_unique
    ])

# Buat dataframe ringkasan
df_desc = pd.DataFrame(
    list_of_descs,
    columns=[
        'Column',
        'Type',
        'Total Rows',
        'Null Count',
        'Null %',
        'Unique Values',
        'Sample Unique Values'
    ]
)

# Tampilkan ringkasan
df_desc

"""### üìù Ringkasan Dataset `movies.csv`

* **movieId** (`int64`)
  ‚Üí ID unik film, total 9742, **tidak ada duplikat atau null**.

* **title** (`object`)
  ‚Üí Judul film, ada **5 duplikat judul** (9737 unik dari 9742), **tidak ada null**.

* **genres** (`object`)
  ‚Üí Gabungan genre (dipisah `|`), total **951 kombinasi unik**, **tidak ada null**.

## Ratings Dataset
"""

ratings.head()

# List untuk menyimpan ringkasan per kolom
list_of_descs = []

# Menggunakan dataframe 'ratings'
for col in ratings.columns:
    col_type = ratings[col].dtype
    total_row = ratings.shape[0]
    null_count = ratings[col].isna().sum()
    null_pct = round((null_count / total_row) * 100, 2)
    unique_count = ratings[col].nunique()
    sample_unique = ratings[col].unique()

    list_of_descs.append([
        col,
        col_type,
        total_row,
        null_count,
        null_pct,
        unique_count,
        sample_unique
    ])

# Buat dataframe ringkasan
df_desc = pd.DataFrame(
    list_of_descs,
    columns=[
        'Column',
        'Type',
        'Total Rows',
        'Null Count',
        'Null %',
        'Unique Values',
        'Sample Unique Values'
    ]
)

# Tampilkan ringkasan
df_desc

"""### üìù Ringkasan Dataset `ratings.csv`

* **userId** (`int64`)
  ‚Üí ID unik pengguna, total 100,836 baris, **610 user unik**, **tidak ada null**.

* **movieId** (`int64`)
  ‚Üí ID unik film, total 100,836 baris, **9,724 film unik**, **tidak ada null**.

* **rating** (`float64`)
  ‚Üí Nilai rating film (skala 0.5‚Äì5.0), total 10 nilai berbeda, **tidak ada null**.

* **timestamp** (`int64`)
  ‚Üí Waktu rating dalam format epoch, total 85,043 nilai unik, **tidak ada null**.

"""

import matplotlib.pyplot as plt
import seaborn as sns

# Hitung jumlah kemunculan setiap rating
rating_counts = ratings['rating'].value_counts().sort_index()

plt.figure(figsize=(10, 6))
ax = sns.barplot(x=rating_counts.index, y=rating_counts.values, hue=rating_counts.index, palette="viridis", legend=False)
plt.title('Distribusi Jumlah Rating')
plt.xlabel('Rating')
plt.ylabel('Jumlah Pengguna')

# Tambahkan label besarannya di atas setiap bar
for container in ax.containers:
    ax.bar_label(container)

plt.show()

"""### üìä **Hasil Visualisasi**

* **Rating 4.0** menjadi rating yang paling banyak diberikan oleh pengguna, dengan jumlah mencapai **26.818 kali**. Hal ini menunjukkan bahwa sebagian besar pengguna memberikan penilaian positif terhadap film yang mereka tonton.

* Rating **3.0** juga sangat sering diberikan, sebanyak **20.047 kali**, diikuti oleh rating **5.0** (**13.211 kali**) dan **3.5** (**13.136 kali**). Pola ini menunjukkan bahwa mayoritas pengguna cenderung memberikan rating di rentang **tengah ke atas**, yaitu antara **3.0 hingga 5.0**.

* Rating paling rendah, yaitu **0.5**, sangat jarang diberikan, hanya sebanyak **1.370 kali**, diikuti oleh rating **1.5 (1.791 kali)** dan **1.0 (2.811 kali)**. Ini menunjukkan bahwa hanya sedikit pengguna yang benar-benar tidak menyukai film yang mereka tonton.

* **Distribusi ini bersifat skewed ke kanan**, artinya lebih banyak pengguna yang memberikan penilaian positif dibanding negatif. Hal ini bisa mencerminkan dua hal:

  1. Film yang ditonton umumnya berkualitas baik atau sesuai dengan preferensi pengguna.
  2. Pengguna cenderung memberikan penilaian lebih tinggi karena faktor subjektif seperti aktor favorit, alur cerita yang menarik, atau faktor nostalgia.

# Data Preprocessing

## Merge Data `movies` dan `ratings`
"""

df_merge = pd.merge(movies, ratings, on='movieId',  how='left')
df_merge.head()

# Hitung jumlah kemunculan setiap judul film
title_counts = df_merge['title'].value_counts()

# Ambil top 20 judul film yang paling sering muncul
top_titles = title_counts.head(20)

plt.figure(figsize=(12, 8))
ax = sns.barplot(x=top_titles.values, y=top_titles.index, palette='viridis', hue=top_titles.index, legend=False)
plt.title('Distribusi Jumlah Title Film (Top 20)')
plt.xlabel('Jumlah Kemunculan')
plt.ylabel('Judul Film')

# Tambahkan label besarannya di setiap bar
for container in ax.containers:
    ax.bar_label(container, fmt='%d')

plt.tight_layout()
plt.show()

"""### üìä **Hasil Visualisasi**

* Film **Forrest Gump (1994)** menjadi film dengan **jumlah kemunculan terbanyak** dalam dataset, yaitu sebanyak **329 kali**, diikuti oleh **The Shawshank Redemption (1994)** (**317 kali**) dan **Pulp Fiction (1994)** (**307 kali**). Hal ini menunjukkan bahwa film-film ini sangat populer dan sering dinilai oleh pengguna.

* Sebagian besar film yang masuk dalam 20 besar berasal dari **dekade 1990-an**, menunjukkan bahwa era ini mendominasi dalam hal jumlah film yang menarik perhatian pengguna. Beberapa film dari tahun 1980-an dan 2000-an juga muncul, seperti *Star Wars: Episode V (1980)* dan *The Lord of the Rings: The Fellowship of the Ring (2001)*.

* Genre yang dominan dalam daftar ini mencakup **Drama, Crime, Adventure, dan Sci-Fi**, menandakan bahwa pengguna cenderung lebih banyak menonton dan memberi penilaian pada film-film dengan narasi yang kuat dan mendalam.

* Menariknya, film **animasi dan keluarga** seperti *Toy Story (1995)* juga masuk ke dalam daftar ini, menunjukkan bahwa genre keluarga tetap memiliki tempat di hati pengguna meskipun lebih sedikit dibanding genre drama atau thriller.

## Menghapus kolom `timestamp`
"""

df_merge = df_merge.drop('timestamp', axis=1)
df_merge.head()

"""menghapus kolom `timestamp` karena tidak digunakan

## Mengatasi Missing Values
"""

df_merge.isna().sum()

"""Data tersebut menunjukkan adanya **missing values** atau nilai yang hilang di beberapa kolom, yaitu:

* Kolom `userId` memiliki 18 nilai kosong.
* Kolom `rating` juga memiliki 18 nilai kosong.
* Sedangkan kolom `movieId`, `title`, dan `genres` tidak memiliki nilai kosong sama sekali.

## Menghapus Missing Values
"""

# Drop rows with missing values
df_merge.dropna(inplace=True)

# Verify that missing values have been removed
df_merge.isna().sum()

"""## Mengatasi data duplikat"""

print(f'Jumlah data duplikat: ', df_merge.duplicated().sum())

"""## Menghapus Simbol pada kolom `title` dan `genres`"""

df_merge['title'] = df_merge['title'].str.replace(r"\((\d{4})\)", r"\1", regex=True)
df_merge['genres'] = df_merge['genres'].str.split('|')

print(df_merge.head())

"""menghapus simbol `|` agar bisa digunakan untuk tahap selanjutnya"""

# Membuat list untuk menyimpan genre yang unik
all_genres = []

# Iterasi melalui setiap baris dataframe
for index, row in df_merge.iterrows():
    # Periksa apakah nilai di kolom 'genres' adalah list
    if isinstance(row['genres'], list):
        # Tambahkan setiap genre dalam list ke list all_genres
        all_genres.extend(row['genres'])
    else:
        if pd.notna(row['genres']): # Pastikan bukan NaN
            all_genres.append(row['genres'])


# Mengubah list menjadi set untuk mendapatkan genre yang unik
unique_genres = set(all_genres)

# Menampilkan jenis unique genres
print("Jenis unique genres:")
for genre in unique_genres:
    print(genre)

print(f'\nJumlah unique genres:', len(unique_genres))

# Explode kolom genres agar satu genre per baris
genres_exploded = df_merge.explode('genres')

# Hitung jumlah film per genre
genre_counts = genres_exploded['genres'].value_counts()

# Ambil top 20 genre
top_genres = genre_counts.head(20)
total_count = genre_counts.sum()  # total semua genre (bisa lebih dari jumlah film karena multi-genre)

# Buat DataFrame
top_genres_df = top_genres.reset_index()
top_genres_df.columns = ['Genre', 'Count']

# Plot
plt.figure(figsize=(12, 8))
ax = sns.barplot(data=top_genres_df, x='Genre', y='Count', hue='Genre', palette='viridis', legend=False)

# Tambahkan label jumlah dan persentase di atas batang
for i, row in top_genres_df.iterrows():
    count = row['Count']
    percent = (count / total_count) * 100
    ax.text(i, count + 1, f'{count}\n({percent:.1f}%)', ha='center', va='bottom', fontsize=9)

# Styling
plt.title('Jumlah Judul Film Berdasarkan Genre')
plt.xlabel('Genre')
plt.ylabel('Jumlah Judul Film')
plt.xticks(rotation=90)
plt.tight_layout()
plt.show()

"""### üìä **Hasil Visualisasi**
- Genre Drama merupakan genre yang paling banyak muncul, dengan 41.928 judul film atau sekitar 15,3% dari total keseluruhan.
- Diikuti oleh Comedy (14,2%), Action (11,2%), dan Thriller (9,6%), yang juga memiliki jumlah film yang cukup tinggi.
- Genre seperti Western, Documentary, dan Film-Noir memiliki jumlah film yang jauh lebih sedikit, masing-masing hanya 0,7%, 0,4%, dan 0,3% dari total.
- Selain itu, terdapat pula kategori (no genres listed) yang mencakup 47 judul film atau sekitar 0,0%, menunjukkan bahwa sejumlah kecil film tidak memiliki genre yang terklasifikasi.

Untuk kategori no genres listed akan dihapus.
"""

# Hitung rata-rata rating per genre
average_rating_per_genre = genres_exploded.groupby('genres')['rating'].mean().sort_values(ascending=False)
# Konversi ke DataFrame untuk visualisasi
average_rating_df = average_rating_per_genre.reset_index()
average_rating_df.columns = ['Genre', 'Average Rating']
plt.figure(figsize=(14, 10)) # Adjust figure size for more genres
ax = sns.barplot(data=average_rating_df, x='Average Rating', y='Genre', hue='Genre', palette='viridis', legend=False)
plt.title('Rata-rata Rating per Genre (Semua Genre)')
plt.xlabel('Rata-rata Rating')
plt.ylabel('Genre')

# Tambahkan label nilai rata-rata rating
for container in ax.containers:
    ax.bar_label(container, fmt='%.2f')

# Optional: Adjust x-axis limits if needed
plt.xlim(average_rating_df['Average Rating'].min() * 0.9, average_rating_df['Average Rating'].max() * 1.1)
plt.tight_layout()
plt.show()

"""### üìä **Hasil Visualisasi**

- Genre **Film-Noir** memiliki **rata-rata rating tertinggi** dibandingkan genre lainnya, yaitu sebesar **3,92**, diikuti oleh genre **War (3,81)** dan **Documentary (3,80)**. Ketiga genre ini menunjukkan kualitas atau apresiasi yang tinggi dari pengguna meskipun jumlah filmnya relatif lebih sedikit dibanding genre populer lainnya.

- Genre seperti **Drama** dan **Crime** juga menunjukkan rating cukup tinggi (**3,66**), menandakan konsistensi kualitas meskipun jumlah judulnya banyak.

- Sebaliknya, genre **Horror** menempati posisi terendah dengan rata-rata rating sebesar **3,26**, diikuti oleh **Comedy (3,38)** dan **Children (3,41)**. Hal ini mungkin mencerminkan selera pengguna yang lebih kritis terhadap genre-genre tersebut atau kualitas yang lebih bervariasi.

- Menariknya, kategori **(no genres listed)** memiliki rata-rata rating **3,49**, menunjukkan bahwa meskipun tidak diklasifikasikan ke dalam genre tertentu, film-film tersebut tetap mendapatkan apresiasi cukup baik dari pengguna.

### Menghapus data pada kolom `title` yang tidak memiliki genre
"""

df_merge = df_merge[df_merge['genres'].apply(lambda x: '(no genres listed)' not in x)]

print(f'Jumlah baris setelah menghapus data dengan "no genres listed":', len(df_merge))
print(df_merge.head())

print("\nJumlah nilai unique pada kolom 'rating' dan jumlahnya:")
print(ratings['rating'].value_counts())

df_merge

"""## Content Based Filtering"""

df_cbf = df_merge[['movieId', 'title', 'genres']]
df_cbf.head()

"""### Penghapusan Data Duplikat Berdasarkan Judul dan Genre"""

# Convert the list of genres back to a string representation for hashing
df_cbf['genres_str'] = df_cbf['genres'].apply(lambda x: '|'.join(x))

# Drop duplicates using the new string column and the title column
df_cbf = df_cbf.drop_duplicates(subset=['title', 'genres_str'])

# You can drop the temporary 'genres_str' column if you no longer need it
df_cbf = df_cbf.drop('genres_str', axis=1)

print("Jumlah baris setelah menghapus duplikat:", len(df_cbf))
df_cbf.head()

"""### TF-IDF Vectorizer"""

from sklearn.feature_extraction.text import TfidfVectorizer

# Inisialisasi TfidfVectorizer
tf = TfidfVectorizer()

# Convert the list of genres into a single string separated by spaces
# This makes the 'genres' column suitable for TfidfVectorizer
df_cbf['genres_string'] = df_cbf['genres'].apply(lambda x: ' '.join(x))

# Fit the TfidfVectorizer on the new string column
tf.fit(df_cbf['genres_string'])

# You can keep the original 'genres' list column or drop it if not needed later
# df_cbf = df_cbf.drop('genres', axis=1)

tf.get_feature_names_out()

df_cbf

"""### Menghapus Kolom `genres`"""

df_cbf = df_cbf.drop('genres', axis=1)
df_cbf.head()

# Melakukan fit lalu ditransformasikan ke bentuk matrix
tfidf_matrix = tf.fit_transform(df_cbf['genres_string'])

# Melihat ukuran matrix tfidf
tfidf_matrix.shape

# Mengubah vektor tf-idf dalam bentuk matriks dengan fungsi todense()
tfidf_matrix.todense()

# Membuat dataframe untuk melihat tf-idf matrix
pd.DataFrame(
    tfidf_matrix.todense(),
    columns=tf.get_feature_names_out(),
    index=df_cbf.title
).sample(21, axis=1).sample(10, axis=0)

"""### Cosine Similarity"""

from sklearn.metrics.pairwise import cosine_similarity

# Menghitung cosine similarity pada matrix tf-idf
cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim # Display the result

# Membuat dataframe dari variabel cosine_sim dengan baris dan kolom berupa nama title
cosine_sim_df = pd.DataFrame(cosine_sim, index=df_cbf['title'], columns=df_cbf['title'])
print('Shape:', cosine_sim_df.shape)

# Melihat similarity matrix pada setiap title
cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

"""### Mendapatkan Rekomendasi"""

def movie_recommendations(movie_title, similarity_data=cosine_sim_df, items=df_cbf[['title', 'genres_string']], k=10):
    """
    Rekomendasi Film berdasarkan kemiripan dataframe
    Parameter:
    ---
    movie_title : tipe data string (str)
                Nama Film (index kemiripan dataframe)
    similarity_data : tipe data pd.DataFrame (object)
                      Kesamaan dataframe, simetrik, dengan judul film sebagai
                      indeks dan kolom
    items : tipe data pd.DataFrame (object)
            Mengandung kedua nama dan fitur lainnya yang digunakan untuk mendefinisikan kemiripan
    k : tipe data integer (int)
        Banyaknya jumlah rekomendasi yang diberikan
    ---
    Pada index ini, kita mengambil k dengan nilai similarity terbesar
    pada index matrix yang diberikan (i).
    """
    # Mengambil data dengan menggunakan argpartition untuk melakukan partisi secara tidak langsung sepanjang sumbu yang diberikan
    # Dataframe diubah menjadi numpy
    # Range(start, stop, step)
    index = similarity_data.loc[:,movie_title].to_numpy().argpartition(
        range(-1, -k, -1))
    # Mengambil data dengan similarity terbesar dari index yang ada
    closest = similarity_data.columns[index[-1:-(k+2):-1]]
    # Drop movie_title agar judul film yang dicari tidak muncul dalam daftar rekomendasi
    closest = closest.drop(movie_title, errors='ignore')
    return pd.DataFrame(closest).merge(items).head(k)

"""### Memasukkan nama `title`"""

df_cbf[df_cbf.title.eq('Clueless 1995')]

"""### Menampilkan rekomendasi yang diberikan berdasarkan `genres`"""

movie_recommendations('Clueless 1995')

"""## Collaborative Filtering"""

df_cf = df_merge[['userId', 'movieId', 'rating']]
df_cf

"""## Data Preparation (Collaborative Filtering)

### Encoding Data
"""

# Mengubah userId menjadi list tanpa nilai yang sama
user_ids = df_cf['userId'].unique().tolist()
print('list userId: ', user_ids)
# Melakukan encoding userId
user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
print('encoded userId : ', user_to_user_encoded)
# Melakukan proses encoding angka ke ke userId
user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}
print('encoded angka ke userId: ', user_encoded_to_user)

# Mengubah movieId menjadi list tanpa nilai yang sama
movie_ids = df_cf['movieId'].unique().tolist()
print('list movieId: ', movie_ids)
# Melakukan encoding movieId
movie_to_movie_encoded = {x: i for i, x in enumerate(movie_ids)}
print('encoded movieId : ', movie_to_movie_encoded)
# Melakukan proses encoding angka ke ke movieId
movie_encoded_to_movie = {i: x for i, x in enumerate(movie_ids)}
print('encoded angka ke movieId: ', movie_encoded_to_movie)

# Mapping userId ke dataframe
df_cf['user'] = df_cf['userId'].map(user_to_user_encoded)
# Mapping movieId ke dataframe
df_cf['movie'] = df_cf['movieId'].map(movie_to_movie_encoded)

# Mendapatkan jumlah user
num_users = len(user_to_user_encoded)
print(f'Jumlah user: {num_users}')

# Mendapatkan jumlah movie
num_movies = len(movie_encoded_to_movie)
print(f'Jumlah movie: {num_movies}')

# Mengubah rating menjadi nilai float
df_cf['rating'] = df_cf['rating'].values.astype(np.float32)

# Nilai minimum rating
min_rating = min(df_cf['rating'])

# Nilai maksimal rating
max_rating = max(df_cf['rating'])

print('Number of User: {}, Number of Movie: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_movies, min_rating, max_rating
))

"""## Mengacak Data

Acak datanya terlebih dahulu agar distribusinya menjadi random. Proses ini bertujuan untuk mengacak urutan data agar distribusinya menjadi lebih acak dan tidak mengikuti pola tertentu
"""

df_cf = df_cf.sample(frac=1, random_state=42)
df_cf

"""## Membagi Data untuk Training dan Validasi"""

from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
X = df_cf[['user', 'movie']].values
y = MinMaxScaler().fit_transform(df_cf[['rating']])

X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=.2, random_state=42)

print(f'Banyaknya data pada X_train: {len(X_train)}')
print(f'Banyaknya data pada y_train: {len(y_train)}')
print(f'Banyaknya data pada X_val: {len(X_val)}')
print(f'Banyaknya data pada y_val: {len(y_val)}')

"""## Modeling Collaborative Filtering"""

import tensorflow as tf
from tensorflow import keras

class RecommenderNet(tf.keras.Model):

  # Insialisasi fungsi
  def __init__(self, num_users, num_resto, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_resto = num_resto
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding( # layer embedding user
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.user_bias = layers.Embedding(num_users, 1) # layer embedding user bias
    self.resto_embedding = layers.Embedding( # layer embeddings resto
        num_resto,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.resto_bias = layers.Embedding(num_resto, 1) # layer embedding resto bias

  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0]) # memanggil layer embedding 1
    user_bias = self.user_bias(inputs[:, 0]) # memanggil layer embedding 2
    resto_vector = self.resto_embedding(inputs[:, 1]) # memanggil layer embedding 3
    resto_bias = self.resto_bias(inputs[:, 1]) # memanggil layer embedding 4

    dot_user_resto = tf.tensordot(user_vector, resto_vector, 2)

    x = dot_user_resto + user_bias + resto_bias

    return tf.nn.sigmoid(x) # activation sigmoid

model = RecommenderNet(num_users, num_movies, 50) # inisialisasi model
# model compile
model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

"""## Evaluation"""

history = model.fit(
    x = X_train,
    y = y_train,
    batch_size = 8,
    epochs = 20,
    validation_data = (X_val, y_val)
)

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('Model RMSE')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""### Mendapatkan Rekomendasi"""

movies_df = movies
df = pd.read_csv('/content/movies-and-ratings-for-recommendation-system/ratings.csv')

# Mengambil sample user
user_id = df['userId'].sample(1).iloc[0]
movies_watched_by_user = df[df['userId'] == user_id]

# Mengambil data film yang belum ditonton user
movies_not_watched = movies_df[~movies_df['movieId'].isin(movies_watched_by_user.movieId.values)]['movieId']
movies_not_watched = list(
    set(movies_not_watched)
    .intersection(set(movie_to_movie_encoded.keys()))
)
movies_not_watched = [[movie_to_movie_encoded.get(x)] for x in movies_not_watched]
user_encoder = user_to_user_encoded.get(user_id)
user_movie_array = np.hstack(
    ([[user_encoder]] * len(movies_not_watched), movies_not_watched)
)

movies_df

"""### Menampilkan rekomendasi"""

# Memprediksi rating
ratings = model.predict(user_movie_array).flatten()

# Mendapatkan top N rekomendasi
top_ratings_indices = ratings.argsort()[-10:][::-1]
recommended_movie_ids = [
    movie_encoded_to_movie.get(movies_not_watched[x][0]) for x in top_ratings_indices
]

print('Showing recommendations for users: {}'.format(user_id))
print('===' * 9)
print('Movie with high ratings from user')
print('----' * 8)

# Top 5 film yang ditonton user
top_movies_user = (
    movies_watched_by_user.sort_values(by='rating', ascending=False)
    .head(5).movieId.values
)
movie_df_rows = movies_df[movies_df['movieId'].isin(top_movies_user)]
for row in movie_df_rows.itertuples():
  print(f"{row.title} (Genres: {row.genres})")

print('----' * 8)
print('Top 10 movie recommendation')
print('----' * 8)

recommended_movies = movies_df[movies_df['movieId'].isin(recommended_movie_ids)]
for row in recommended_movies.itertuples():
  print(f"{row.title} (Genres: {row.genres})")